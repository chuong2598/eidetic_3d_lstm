{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "3hymnPNbIxEk",
    "outputId": "5e8dc46b-8fdb-45a5-8351-f13a22babe1e"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchvision\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# torch.cuda.get_device_name(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "fZ1zghkmJK8s"
   },
   "outputs": [],
   "source": [
    "\n",
    "class ED3LSTMCell(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, input_shape, in_channels, hidden_channels, kernel_size, stride):\n",
    "        super(ED3LSTMCell, self).__init__()\n",
    "        \n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.padding = kernel_size//2\n",
    "        self.stride = stride\n",
    "        \n",
    "        self.r_bias, self.i_bias, self.g_bias, self.i_prime_bias, self.g_prime_bias, self.f_prime_bias, self.o_bias = torch.nn.Parameter(torch.randn(7))\n",
    "        \n",
    "        channel, length, width, height = input_shape\n",
    "\n",
    "        self.conv_x = torch.nn.Sequential(\n",
    "            torch.nn.Conv3d(in_channels=in_channels, out_channels=hidden_channels*7, kernel_size=kernel_size, padding=self.padding, stride=stride),\n",
    "            torch.nn.LayerNorm([hidden_channels*7, length, width, height])\n",
    "        )\n",
    "        \n",
    "        self.conv_h_prev = torch.nn.Sequential(\n",
    "            torch.nn.Conv3d(in_channels=hidden_channels, out_channels=hidden_channels*4, kernel_size=kernel_size, padding=self.padding, stride=stride),\n",
    "            torch.nn.LayerNorm([hidden_channels*4, length, width, height])\n",
    "        )\n",
    "        \n",
    "        self.conv_m_prev = torch.nn.Sequential(\n",
    "            torch.nn.Conv3d(in_channels=hidden_channels, out_channels=hidden_channels*3, kernel_size=kernel_size, padding=self.padding, stride=stride),\n",
    "            torch.nn.LayerNorm([hidden_channels*3, length, width, height])\n",
    "        )\n",
    "        \n",
    "        self.conv_c = torch.nn.Sequential(\n",
    "            torch.nn.Conv3d(in_channels=hidden_channels, out_channels=hidden_channels, kernel_size=kernel_size, padding=self.padding, stride=stride),\n",
    "            torch.nn.LayerNorm([hidden_channels, length, width, height])\n",
    "        )\n",
    "        \n",
    "        self.conv_m = torch.nn.Sequential(\n",
    "            torch.nn.Conv3d(in_channels=hidden_channels, out_channels=hidden_channels, kernel_size=kernel_size, padding=self.padding, stride=stride),\n",
    "            torch.nn.LayerNorm([hidden_channels, length, width, height])\n",
    "        )\n",
    "        \n",
    "        self.layer_norm_c = torch.nn.LayerNorm([hidden_channels, length, width, height])\n",
    "        \n",
    "        self.conv_c_m = torch.nn.Conv3d(in_channels=hidden_channels*2, out_channels=hidden_channels, kernel_size=1, padding=0, stride=1)\n",
    "        \n",
    "    def forward(self, x, h_prev, c_history, m_prev, tau=-1):\n",
    "        batch, channels, length, height, width = x.shape\n",
    "        c_prev = c_history[-1]\n",
    "        if (tau==-1 or tau > len(c_history)):\n",
    "            tau = len(c_history)\n",
    "        c_history = torch.stack(c_history[-tau:])\n",
    "        c_history = c_history.permute(1,0,2,3,4,5)\n",
    "#         c_history = torch.cat([c_history[-i].reshape(batch, 1, self.hidden_channels, length, height, width) for i in range(tau, 0, -1)], dim=1)\n",
    "#         print(c_history.shape)\n",
    "        \n",
    "        conv_x = self.conv_x(x)\n",
    "        r_x, i_x, g_x, i_x_prime, g_x_prime, f_x_prime, o_x = torch.split(tensor=conv_x, split_size_or_sections=self.hidden_channels, dim=1)\n",
    "        conv_h_prev = self.conv_h_prev(h_prev)\n",
    "        r_h, i_h, g_h, o_h = torch.split(tensor=conv_h_prev, split_size_or_sections=self.hidden_channels, dim=1)\n",
    "        \n",
    "        r = torch.sigmoid(r_x + r_h + self.r_bias)\n",
    "        i = torch.sigmoid(i_x + i_h + self.i_bias)\n",
    "        g = torch.tanh(g_x + g_h + self.g_bias)\n",
    "        \n",
    "        # Self attention with query=R and key=value= historical memories c (c_history)\n",
    "        r = r.reshape(batch, length*height*width, self.hidden_channels)\n",
    "        c_history = c_history.reshape(batch, tau*length*height*width, self.hidden_channels)\n",
    "        \n",
    "        print(r.shape)\n",
    "        print(c_history.shape)\n",
    "        # !!!!!!!!!!!!!!! Error here: Tesla V100-SXM2-16GB does not have enough memory to perform softmax !!!!!!!!!!!!!!!\n",
    "        recall = torch.softmax(r @ c_history.permute(0, 2, 1), dim=1) @ c_history \n",
    "        print(recall.shape)\n",
    "        recall = recall.reshape(i.shape)\n",
    "        print(recall.shape)\n",
    "        \n",
    "        c_new = (i * g) + self.layer_norm_c(c_prev + recall)\n",
    "        \n",
    "        conv_m_prev = self.conv_m_prev(m_prev)\n",
    "        i_m_prime, g_m_prime, f_m_prime = torch.split(tensor=conv_m_prev, split_size_or_sections=self.hidden_channels, dim=1)\n",
    "        \n",
    "        i_prime = torch.sigmoid(i_x_prime + i_m_prime + self.i_prime_bias)\n",
    "        g_prime = torch.tanh(g_x_prime + g_m_prime + self.g_prime_bias)\n",
    "        f_prime = torch.sigmoid(f_x_prime + f_m_prime + self.f_prime_bias)\n",
    "        m_new = i_prime*g_prime + f_prime*m_prev\n",
    "        \n",
    "        o_c = self.conv_c(c_new)\n",
    "        o_m = self.conv_m(m_new)\n",
    "        \n",
    "        o = torch.sigmoid(o_x + o_h + o_c + o_m + self.o_bias)\n",
    "        c_m_cat = torch.cat((c_new, m_new), dim = 1)\n",
    "        h_new = o * torch.tanh(self.conv_c_m(c_m_cat))\n",
    "        \n",
    "        return h_new, c_new, m_new\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1DBly7LhJMux"
   },
   "outputs": [],
   "source": [
    "\n",
    "class ED3LSTM(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, nb_layers, encoder_hidden_layer_dim, input_shape, in_channel, hidden_layer_dim, kernel_size, stride):\n",
    "        super(ED3LSTM, self).__init__()\n",
    "        \n",
    "        self.nb_layers = nb_layers\n",
    "        self.hidden_layer_dim = hidden_layer_dim\n",
    "        \n",
    "        channels, length, height, width = input_shape\n",
    "        \n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Conv3d(in_channels=channels, out_channels=encoder_hidden_layer_dim, kernel_size=kernel_size, padding=kernel_size//2, stride=1)\n",
    "        )\n",
    "        \n",
    "        ed3_lstm_cells = []\n",
    "        for i in range(nb_layers):\n",
    "            if i == 0:\n",
    "                new_cell = ED3LSTMCell(input_shape=input_shape, in_channels=encoder_hidden_layer_dim, hidden_channels=hidden_layer_dim, kernel_size=kernel_size, stride=stride)\n",
    "            else:\n",
    "                new_cell = ED3LSTMCell(input_shape=input_shape, in_channels=hidden_layer_dim, hidden_channels=hidden_layer_dim, kernel_size=kernel_size, stride=stride)\n",
    "            ed3_lstm_cells.append(new_cell)\n",
    "            \n",
    "        self.ed3_lstm_cells = torch.nn.ModuleList(ed3_lstm_cells)\n",
    "\n",
    "        \n",
    "        \n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Conv3d(in_channels=hidden_layer_dim, out_channels=channels, kernel_size=(window_size, 1, 1), padding=0, stride=(window_size, 1, 1))\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def forward(self, input_sequence, device=\"cuda\", tau=-1):\n",
    "        \"\"\"batch_sequence: tensor with shape (batch, channel, nb_element, window_size, height, width) containing batch of slided consecutive frames.\"\"\"\n",
    "        batch, channel, nb_element, window_size, height, width = input_sequence.shape\n",
    "        \n",
    "        \n",
    "        # 1-D list with length nb_layers including h of each layers\n",
    "        h_list = []\n",
    "        # 2-D list. The first dimension represent list of cell memory of a specific layer.\n",
    "        # Length of first dimention is nb_layers. Length of second dimension is nb_element (i.e number of timesteps)\n",
    "        # The element in the second dimension is a tensor representating a cell memeory at a specific layer and a specific timestep\n",
    "        c_list = []\n",
    "        # Store list of prediction\n",
    "        prediction = []\n",
    "        for layer in range(self.nb_layers):\n",
    "            h_list.append(torch.zeros(batch, self.hidden_layer_dim, window_size, height, width, device=device))\n",
    "            c_list.append([])\n",
    "            for time_step in range(nb_element):\n",
    "                c_list[layer].append(torch.zeros(batch, self.hidden_layer_dim, window_size, height, width, device=device))\n",
    "        \n",
    "        memory = torch.zeros(batch, self.hidden_layer_dim, window_size, height, width, device=device)\n",
    "        for time_step in range(nb_element):\n",
    "            print(\"time_step: \", time_step)\n",
    "            encoder_output = self.encoder(input_sequence[:,:,time_step])\n",
    "            c_history = c_list[0][:time_step+1]\n",
    "            print(\"layer: \", 0)\n",
    "            h_list[0], c_list[0][time_step], memory = self.ed3_lstm_cells[0](encoder_output, h_list[0], c_history, memory, tau=tau)\n",
    "            \n",
    "            for layer in range(1, self.nb_layers):\n",
    "                print(\"layer: \", layer)\n",
    "                c_history = c_list[layer][:time_step+1]\n",
    "                h_list[layer], c_list[layer][time_step], memory = self.ed3_lstm_cells[layer](h_list[layer-1], h_list[layer], c_history, memory, tau=tau)\n",
    "            print()\n",
    "            timestep_prediction = self.decoder(h_list[-1])\n",
    "            prediction.append(timestep_prediction)\n",
    "#         return prediction\n",
    "        prediction = torch.stack(prediction).squeeze(dim=2).permute(1,0,2,3,4)\n",
    "        return prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "DM9Lbk4hI4Sn"
   },
   "outputs": [],
   "source": [
    "\n",
    "def extract_slided_sequence(batch_sequences, window_size=2, window_stride=1):\n",
    "    batch, channels, length, height, width  = batch_sequences.shape\n",
    "    nb_elements = (length - window_size) // window_stride + 1\n",
    "    slided_sequences = torch.zeros(batch, channels, nb_elements, window_size, height, width)\n",
    "    \n",
    "    for i in range(0, length - window_size+1, window_stride):\n",
    "        element = batch_sequences[:, :, i:i+window_size, ...]\n",
    "        slided_sequences[:,:,i//window_stride,:,:,:] = element\n",
    "    return slided_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "JIyyrI9JTtxy"
   },
   "outputs": [],
   "source": [
    "# from pynvml import *\n",
    "# nvmlInit()\n",
    "# h = nvmlDeviceGetHandleByIndex(0)\n",
    "# info = nvmlDeviceGetMemoryInfo(h)\n",
    "# print(f'total    : {info.total}')\n",
    "# print(f'free     : {info.free}')\n",
    "# print(f'used     : {info.used}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "I_NPz9WeJS_v"
   },
   "outputs": [],
   "source": [
    "\n",
    "# # !!! X train of shape batch x channel x nb_element x window_size x height x width\n",
    "window_size = 8\n",
    "window_stride = 1\n",
    "\n",
    "# # Load dataset\n",
    "training_set =  np.load(\"./mnist_train_seq.npy\")\n",
    "training_set = training_set.reshape(80000, 20, 1, 64, 64)\n",
    "x_train, y_train = torch.tensor(training_set[:10000, :10, ...]).float(), torch.tensor(training_set[:10000, window_size:10+window_size, ...]).float()\n",
    "x_train = x_train.permute(0, 2, 1, 3, 4)\n",
    "y_train = y_train.permute(0, 2, 1, 3, 4)\n",
    "\n",
    "testing_set = np.load(\"./mnist_test_seq.npy\")\n",
    "testing_set = testing_set.reshape(10000, 20, 1, 64, 64)\n",
    "x_val, y_val = torch.tensor(testing_set[:5000, :10, ...]).float(), torch.tensor(testing_set[:5000, window_size:10+window_size, ...]).float()\n",
    "x_val = x_val.permute(0, 2, 1, 3, 4)\n",
    "y_val = y_val.permute(0, 2, 1, 3, 4)\n",
    "\n",
    "x_test, y_test = torch.tensor(testing_set[5000:, :10, ...]).float(), torch.tensor(testing_set[5000:, window_size:10+window_size, ...]).float()\n",
    "x_test = x_test.permute(0, 2, 1, 3, 4)\n",
    "y_test = y_test.permute(0, 2, 1, 3, 4)\n",
    "\n",
    "del testing_set\n",
    "del training_set\n",
    "\n",
    "# Extract training, validation, testing set\n",
    "x_train = extract_slided_sequence(x_train, window_size, window_stride)\n",
    "x_val = extract_slided_sequence(x_val, window_size, window_stride)\n",
    "x_test = extract_slided_sequence(x_test, window_size, window_stride)\n",
    "\n",
    "training_set = DataLoader(TensorDataset(x_train, y_train), batch_size=2, shuffle=True)\n",
    "validation_set = DataLoader(TensorDataset(x_val, y_val), batch_size=2, shuffle=False)\n",
    "testing_set = DataLoader(TensorDataset(x_test, y_test), batch_size=2, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "x50vPUqcJaKX"
   },
   "outputs": [],
   "source": [
    "\n",
    "channels = 1\n",
    "height = 64\n",
    "width = 64\n",
    "nb_layers = 4\n",
    "encoder_hidden_layer_dim = 3\n",
    "hidden_layer_dim = 64\n",
    "kernel_size = 5\n",
    "stride = 1\n",
    "tau = -1\n",
    "\n",
    "# Init model, parameters\n",
    "ed3_lstm = ED3LSTM(nb_layers=nb_layers, encoder_hidden_layer_dim=encoder_hidden_layer_dim, input_shape=(channels, window_size, height, width), \n",
    "                   in_channel=channels, hidden_layer_dim=hidden_layer_dim, kernel_size=kernel_size, stride=stride)\n",
    "ed3_lstm.to(device=device)\n",
    "optim = torch.optim.Adam(ed3_lstm.parameters())\n",
    "l1_loss = torch.nn.L1Loss()\n",
    "l2_loss = torch.nn.MSELoss()\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "current_epoch = 0\n",
    "epochs = 20\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424,
     "referenced_widgets": [
      "1591167481f34f28886663563a1251c3",
      "cb3f40b6ed5a4d5b87d446eb94922642",
      "2407e15b20c0463dbec1574eadf0e396",
      "7df533cdfe904a3ebac384786593163c",
      "6861782b30184caba5e72520812c65ee",
      "38b8cce0978b45e8a81f211aaa84e68d",
      "54c0dfb3c2d44647ac690522a9e946da",
      "ba94e71c31c3426f909be49bee9a2dcf"
     ]
    },
    "id": "lfA27TwAJw8N",
    "outputId": "15e8af91-15a5-4ac8-b7fe-4c0cc73971da"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8d22cb9864a48409d5dc4275af83e19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_step:  0\n",
      "layer:  0\n",
      "torch.Size([2, 32768, 8])\n",
      "torch.Size([2, 32768, 8])\n",
      "torch.Size([2, 32768, 8])\n",
      "torch.Size([2, 8, 8, 64, 64])\n",
      "layer:  1\n",
      "torch.Size([2, 32768, 8])\n",
      "torch.Size([2, 32768, 8])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for sequence, target in tqdm(training_set):\n",
    "    sequence = sequence.to(device=device)\n",
    "    target = target.to(device=device)\n",
    "    pred = ed3_lstm(sequence, device=device, tau=tau)\n",
    "    loss = l2_loss(pred, target) + l1_loss(pred, target)\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    print(loss.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aeY2s-0xJ5zZ"
   },
   "outputs": [],
   "source": [
    "\n",
    "# a = torch.randn(4, 3, 5, 64, 64)\n",
    "# conv = torch.nn.Conv3d(in_channels=3, out_channels=4, kernel_size=(2,5,5), stride=1, padding=(1,2,2))\n",
    "# b = conv(a)\n",
    "# b.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "ed3_lstm.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1591167481f34f28886663563a1251c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2407e15b20c0463dbec1574eadf0e396",
       "IPY_MODEL_7df533cdfe904a3ebac384786593163c"
      ],
      "layout": "IPY_MODEL_cb3f40b6ed5a4d5b87d446eb94922642"
     }
    },
    "2407e15b20c0463dbec1574eadf0e396": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "  0%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_38b8cce0978b45e8a81f211aaa84e68d",
      "max": 5000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6861782b30184caba5e72520812c65ee",
      "value": 0
     }
    },
    "38b8cce0978b45e8a81f211aaa84e68d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "54c0dfb3c2d44647ac690522a9e946da": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6861782b30184caba5e72520812c65ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "7df533cdfe904a3ebac384786593163c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ba94e71c31c3426f909be49bee9a2dcf",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_54c0dfb3c2d44647ac690522a9e946da",
      "value": " 0/5000 [00:00&lt;?, ?it/s]"
     }
    },
    "ba94e71c31c3426f909be49bee9a2dcf": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb3f40b6ed5a4d5b87d446eb94922642": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
